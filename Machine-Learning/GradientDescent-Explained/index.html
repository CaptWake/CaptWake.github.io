<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Gradient Descent explained - Personal Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Personal Blog"><meta name="msapplication-TileImage" content="/images/favicons/favicon.ico"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Personal Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="First of all let me ask what is an optimization problem? An optimization task refers to minimize or maximize a given function $f(x)$ by modifying $x$..."><meta property="og:type" content="blog"><meta property="og:title" content="Gradient Descent explained"><meta property="og:url" content="https://captwake.github.io/Machine-Learning/GradientDescent-Explained/"><meta property="og:site_name" content="Personal Blog"><meta property="og:description" content="First of all let me ask what is an optimization problem? An optimization task refers to minimize or maximize a given function $f(x)$ by modifying $x$..."><meta property="og:locale" content="en_US"><meta property="og:image" content="https://www.offconvex.org/assets/saddle/minmaxsaddle.png"><meta property="og:image" content="https://captwake.github.io/images/Machine_Learning/sgd_vs_adam.gif"><meta property="article:published_time" content="2023-08-24T00:00:00.000Z"><meta property="article:modified_time" content="2023-09-07T09:16:08.818Z"><meta property="article:author" content="Stefano De Rosa"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://www.offconvex.org/assets/saddle/minmaxsaddle.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://captwake.github.io/Machine-Learning/GradientDescent-Explained/"},"headline":"Gradient Descent explained","image":["https://www.offconvex.org/assets/saddle/minmaxsaddle.png","https://captwake.github.io/images/Machine_Learning/sgd_vs_adam.gif"],"datePublished":"2023-08-24T00:00:00.000Z","dateModified":"2023-09-07T09:16:08.818Z","author":{"@type":"Person","name":"Stefano De Rosa"},"publisher":{"@type":"Organization","name":"Personal Blog","logo":{"@type":"ImageObject","url":"https://captwake.github.io/images/favicons/favicon-16x16.png"}},"description":"First of all let me ask what is an optimization problem? An optimization task refers to minimize or maximize a given function $f(x)$ by modifying $x$..."}</script><link rel="canonical" href="https://captwake.github.io/Machine-Learning/GradientDescent-Explained/"><link rel="icon" href="/images/favicons/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/favicons/favicon-16x16.png" alt="Personal Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-3 is-size-4-mobile">Gradient Descent explained</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-alt"></i> <span class="level-item"><time dateTime="2023-08-24T00:00:00.000Z" title="8/24/2023, 12:00:00 AM"> 2023-08-24</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/categories/Machine-Learning/">Machine Learning</a></span><span class="level-item"><i class="far fa-clock"></i>  15 minutes read</span></div></div><div class="content"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>First of all let’s define what is an optimization problem. An optimization task refers to minimize or maximize a given function $f(x)$ by modifying $x$.</p>
<p>The function $f(x)$ is also called <em>objective function</em>, <em>criterion</em>, or also <em>loss function</em>, <em>cost function</em>.</p>
<p>Given a loss function $f(x)$, we can denote its slope at $x$ with $\frac {d y} {d x}$ or equivalently $f’(x)$ (its derivative). As we know the derivative tells us how much the function increases when we increase by a small step $\eta$ called <em>learning rate</em>. So if we want to minimize the loss function we have to move $x$ in the opposite direction described by the gradient of the loss function <em>w.r.t</em> $x$. This is the basic idea behind the gradient descent algorithm.</p>
<p>But how do we search this minimum? If $f’(x) &#x3D; 0$ the derivative gives no information about the direction to go, so it should be reasonable to consider it the minimum.</p>
<p>The $x$ where $x &#x3D; \text{arg} \ f’(x) &#x3D; 0$ and $x &#x3D; \text{arg min} f(x)$ is called global minimum.</p>
<p>Whenever the derivative $f’(x)$ is nonzero, as long as we choose a small enough step, the algorithm is guaranteed to make local progress. When the gradient is equal to $0$, the point is called a critical point, and the gradient descent algorithm will get stuck. For (strongly) convex functions, there is a unique critical point which is also the global minimum.</p>
<p><img src="https://www.offconvex.org/assets/saddle/minmaxsaddle.png" alt="Local Minima vs Local Maxima vs Saddle Point"> To distinguish these cases we need to consider the second order derivative $f’’(x)$, in particular we have to analyze the relative Hessian matrix.</p>
<p>The gradient descent algorithm iteratively exploits the derivative of the loss function to compute the next point as follows:</p>
<p>$$<br>\begin{equation}<br>    x’ &#x3D; x - \eta \nabla_x f(x)<br>\label{eq:basic_GD}<br>\end{equation}<br>$$</p>
<p>In the machine learning literature, we often use the notation $J(\theta)$ or $\mathcal L(\theta)$ to denote the $f(x)$ loss function, where $\theta$ represents the parameters of the model that we want to optimize.</p>
<p>The following code snippet shows an example of how the gradient descent algorithm might be implemented:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line">  params_grad = compute_grads(loss_fn, data, params)</span><br><span class="line">  params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure>

<p>Okay, now you might ask how we can efficiently compute the gradient for each parameter, since the number of trainable parameters for some of the most used language models like BERT have millions of parameters to optimize, and even bigger models like GPT-3 have billions of parameters!.<br>To answer this question, we use a technique called backward mode differentiation (I will probably explain this in the next post of this machine learning series), the basic idea is to use the chain rule to compute the gradients with efficient matrix product multiplication.</p>
<article class="message is-warning">
        <div class="message-header"><p><i class="fa-solid fa-triangle-exclamation mr-2"></i>Warning</p>
</div>
        <div class="message-body">
            <p>A careful reader might also notice that the gradients are computed using all the data, which could be memory expensive if we have a lot of data.</p>

        </div>
    </article>

<h2 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h2><p>To overcome the gradient computation problem for large datasets we could compute the gradient for each sample of the dataset. This method is also called Stochastic Gradient Descent.<br>We modify the update equation as follows:<br>$$\theta &#x3D; \theta - \eta \cdot \nabla_\theta J( \theta; x^{(i)}; y^{(i)})$$<br>where $x^{(i)}$ and $y^{(i)}$ are the feature sample and the label, respectively.<br>The optimization routine can also be modified as shown is the following snippet:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_epochs): </span><br><span class="line">  <span class="keyword">for</span> example <span class="keyword">in</span> data: </span><br><span class="line">    params_grad = compute_grads(loss_fn, example, params) </span><br><span class="line">    params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure>

<article class="message is-primary">
        <div class="message-header"><p><i class="fa-solid fa-magnifying-glass mr-2"></i>Note</p>
</div>
        <div class="message-body">
            <p>Since SGD performs parameter update for each sample in the dataset, these updates have an high variance, causing the objective function to fluctuate heavily. These fluctuations allow in some cases to escape the local minima by jumping to other new potentially better minima. On the other hand, this makes it difficult to converge to the exact minimum, as SGD will keep overshooting.</p>

        </div>
    </article>

<h3 id="Mini-Batch-GD"><a href="#Mini-Batch-GD" class="headerlink" title="Mini-Batch GD"></a>Mini-Batch GD</h3><p>This method takes the best of both worlds by computing the gradients for each batch of the dataset containing $n$ samples. We can formalize the updating rule, taking into account the dataset’s batch as follows:<br>$$\theta &#x3D; \theta - \eta \cdot \nabla_\theta J( \theta; x^{(i:i+n)}; y^{(i:i+n)})$$<br>The optimization routine can also be modified as shown is the following snippet:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_epochs): </span><br><span class="line">  <span class="keyword">for</span> batch <span class="keyword">in</span> data: </span><br><span class="line">    params_grad = compute_grads(loss_fn, batch, params) </span><br><span class="line">    params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure>
<p>The larger the batch size, the more stable the convergence, and we can also efficiently compute batch parameter updates using libraries such as pytorch, tensorflow, etc.</p>
<h3 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h3><p>All of the algorithms described above can be implemented in python.<br>Inspired by the pytorch notation, we, first defined an interface called <code>Optimizer</code>, which defines two methods, <code>step()</code> and <code>zero_grad()</code>. The former is used to update the parameters and the latter is used to zero the gradients.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Optimizer</span>():</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self</span>): <span class="keyword">pass</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">zero_grad</span>(<span class="params">self</span>): <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>We then define the SGD optimizer as follows:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SGD</span>(<span class="title class_ inherited__">Optimizer</span>):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, </span></span><br><span class="line"><span class="params">        params: Iterable[nn.Parameter],  </span></span><br><span class="line"><span class="params">        lr: <span class="built_in">float</span> = <span class="number">0.001</span></span>):</span><br><span class="line">    self.params = params</span><br><span class="line">    self.lr = lr</span><br><span class="line"></span><br><span class="line"><span class="meta">  @torch.no_grad()</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> self.params:</span><br><span class="line">      grad = param.grad</span><br><span class="line">      </span><br><span class="line">      <span class="comment"># update param</span></span><br><span class="line">      param.sub_(self.lr * grad)</span><br><span class="line"></span><br><span class="line"><span class="meta">  @torch.no_grad()</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">zero_grad</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> self.params:</span><br><span class="line">      param.grad = torch.zeros_like(param)</span><br></pre></td></tr></table></figure>

<p>Now we can instantiate it and then integrate in the pytorch routine to optimize the model parameters. Note that this is a simple implementation of the algorithm, there are more efficient implementations also for sparse gradients.</p>
<h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><p>The previous algorithms use a static learning rate defined a priori, we can do better. We can think of adapting the learning rate based on the surface. For example, if we have a steepest descent, we would increase the learning rate, and if we are reaching a saddle point, we might decrease the learning rate instead. This is the basic idea behind the family of algorithms that extend the basic GD algorithm, one of which is Adaptive Moment Estimation (Adam).<br>This algorithm computes an adaptive learning rate for each parameter based on the average first moment, also makes use of the average of the second moments of the gradients.<br>More in details, this algorithm calculates the exponential moving average of gradients and square gradients. And the parameters $\beta_1$ and $\beta_2$ are used to control the decay rates of these moving averages. We can decompose Adam as a combination of two gradient descent methods, Momentum, and RMSP (Root Mean Square Propagation).</p>
<p>First we compute the decaying averages of past gradients and also squared denoted respectively as $m_t$ and $v_t$ as follows:</p>
<p>$$\begin{align}<br>m_t &amp;&#x3D; \beta_1 m_{t-1} + (1 - \beta_1) g_t \\<br>v_t &amp;&#x3D; \beta_2 v_{t-1} + (1 - \beta_2) g_t^2<br>\end{align}$$</p>
<p>where $g_t$ represents the gradient. We can see that $m_t$ corresponds to the estimation of the mean and $v_t$ the variance not centered (2nd moment).</p>
<p>Now we can update the parameters using the following equation:</p>
<p>$$<br>\theta_{t+1} &#x3D; \theta_{t} - \dfrac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t<br>$$</p>
<article class="message is-primary">
        <div class="message-header"><p><i class="fa-solid fa-magnifying-glass mr-2"></i>Note</p>
</div>
        <div class="message-body">
            <p>In the previous equation we update the parameters using the bias corrected moments $\hat{m_t}$ and $\hat{v_t}$ for better stability. These values are computed as follows:<br>$$\begin{align}<br>    \hat{m}_t &amp;&#x3D; \dfrac{m_t}{1 - \beta^t_1} \\<br>    \hat{v}_t &amp;&#x3D; \dfrac{v_t}{1 - \beta^t_2}<br>    \end{align}$$ </p>

        </div>
    </article>

<h3 id="Implementation-1"><a href="#Implementation-1" class="headerlink" title="Implementation"></a>Implementation</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Adam</span>(<span class="title class_ inherited__">Optimizer</span>):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, params: Iterable[nn.Parameter], </span></span><br><span class="line"><span class="params">          lr: <span class="built_in">float</span> = <span class="number">0.001</span>, </span></span><br><span class="line"><span class="params">          betas: <span class="type">Tuple</span>[<span class="built_in">float</span>, <span class="built_in">float</span>] = (<span class="params"><span class="number">0.9</span>, <span class="number">0.999</span></span>), </span></span><br><span class="line"><span class="params">          eps: <span class="built_in">float</span> = <span class="number">1e-08</span></span>):</span><br><span class="line">    self.params = params</span><br><span class="line">    self.m = <span class="number">0.0</span></span><br><span class="line">    self.v = <span class="number">0.0</span></span><br><span class="line">    self.lr = lr</span><br><span class="line">    self.betas = betas</span><br><span class="line">    self.eps = eps</span><br><span class="line">    self.t = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  @torch.no_grad()</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self</span>):</span><br><span class="line">    beta_1, beta_2 = self.betas</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> self.params:</span><br><span class="line">      grad = param.grad</span><br><span class="line">      self.m = beta_1 * self.m + (<span class="number">1</span> - beta_1) * grad</span><br><span class="line">      self.v = beta_2 * self.v + (<span class="number">1</span> - beta_2) * grad.<span class="built_in">pow</span>(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># bias correction</span></span><br><span class="line">      m_hat = self.m / (<span class="number">1.0</span> - beta_1 ** self.t)</span><br><span class="line">      v_hat = self.v / (<span class="number">1.0</span> - beta_2 ** self.t)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># update param</span></span><br><span class="line">      param.sub_(self.lr / (torch.sqrt(v_hat) + self.eps) * m_hat)</span><br><span class="line">    self.t += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  @torch.no_grad()</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">zero_grad</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> self.params:</span><br><span class="line">      param.grad = torch.zeros_like(param)</span><br></pre></td></tr></table></figure>

<h2 id="AdamW"><a href="#AdamW" class="headerlink" title="AdamW"></a>AdamW</h2><p>The $L^2$ regularization is a classic method used to reduce overfitting. This method basically consists in adding the sum of squared parameters (weights) of the model to the loss function, multiplied by a given hyper-parameter $\lambda$ also called weight decay. We can formalize the $L^2$ regularization as follows:<br>$$<br>\tilde J(\theta; x, y) &#x3D; J(\theta; x, y) + \frac \lambda 2 \sum_i \theta_i^2<br>$$</p>
<p>Instead of modifying the loss function, we could instead simply modify the update equation to also subtract a portion of the paramater when updating it using a tecnique called weight decay. The update function would be:<br>$$<br>\theta &#x3D; \theta - \eta \cdot \nabla_\theta J(\theta; x, y) - \eta \lambda \theta<br>$$ </p>
<article class="message is-warning">
        <div class="message-header"><p><i class="fa-solid fa-triangle-exclamation mr-2"></i>Warning</p>
</div>
        <div class="message-body">
            <p>From the equation $\frac {\partial \theta^2} {\partial \theta_i} &#x3D; 2 \theta_i $ we see how we subtract a little portion of the weight at each step, hence the name decay. This should be not confused with the $L^2$ regularization, although are similar in a way, they are only the same thing for vanilla SGD, but as soon as we add momentum, or use a more sophisticated optimizer like Adam, become different.</p>

        </div>
    </article>

<p>So, we have two methods that we could use to prevent overfitting, which one is the best? Luckily, Ilya Loshchilov and Frank Hutter answer this question suggesting in their <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.05101">article</a> that we should prefer the weight decay with Adam (hence the name AdamW), instead of the $L^2$ regularization.</p>
<h3 id="Implementation-2"><a href="#Implementation-2" class="headerlink" title="Implementation"></a>Implementation</h3><p>The implementation is straightforward, we only need to modify the <code>step()</code> method of the Adam optimizer adding the weight decay equation in line 24.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AdamW</span>(<span class="title class_ inherited__">Optimizer</span>):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, params,</span></span><br><span class="line"><span class="params">        Iterable[nn.Parameter], </span></span><br><span class="line"><span class="params">        lr: <span class="built_in">float</span> = <span class="number">0.001</span>, </span></span><br><span class="line"><span class="params">        betas: <span class="type">Tuple</span>[<span class="built_in">float</span>, <span class="built_in">float</span>] = (<span class="params"><span class="number">0.9</span>, <span class="number">0.999</span></span>), </span></span><br><span class="line"><span class="params">        eps: <span class="built_in">float</span> = <span class="number">1e-08</span>,</span></span><br><span class="line"><span class="params">        weight_decay = <span class="number">0.01</span></span>):</span><br><span class="line">    self.params = params</span><br><span class="line">    self.m = <span class="number">0.0</span></span><br><span class="line">    self.v = <span class="number">0.0</span></span><br><span class="line">    self.lr = lr</span><br><span class="line">    self.betas = betas</span><br><span class="line">    self.eps = eps</span><br><span class="line">    self.weight_decay = weight_decay</span><br><span class="line">    self.t = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  @torch.no_grad()</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">step</span>(<span class="params">self</span>):</span><br><span class="line">    beta_1, beta_2 = self.betas</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> self.params:</span><br><span class="line">      grad = param.grad</span><br><span class="line"></span><br><span class="line">      <span class="comment"># weight decay</span></span><br><span class="line">      grad.sub_(self.lr * self.weight_decay * grad)</span><br><span class="line"></span><br><span class="line">      self.m = beta_1 * self.m + (<span class="number">1</span> - beta_1) * grad</span><br><span class="line">      self.v = beta_2 * self.v + (<span class="number">1</span> - beta_2) * grad.<span class="built_in">pow</span>(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># bias correction</span></span><br><span class="line">      m_hat = self.m / (<span class="number">1.0</span> - beta_1 ** self.t)</span><br><span class="line">      v_hat = self.v / (<span class="number">1.0</span> - beta_2 ** self.t)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># update param</span></span><br><span class="line">      param.sub_(self.lr / (torch.sqrt(v_hat) + self.eps) * m_hat)</span><br><span class="line">      self.t += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  @torch.no_grad()</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">zero_grad</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">for</span> param <span class="keyword">in</span> self.params:</span><br><span class="line">      param.grad = torch.zeros_like(param)</span><br></pre></td></tr></table></figure>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>In this section we test the implemented algorithms on a classical quadratic convex loss function $f(x) &#x3D; x^2$, so we have only one minimum with a cool descent.</p>

<div>
    <script type="text/javascript">
        window.PlotlyConfig = {MathJaxConfig: 'local'};
    </script>
    <script type="text/javascript" src="/javascript/plotly.js"></script>
    <div id="c09f34dc-93b7-40fe-8ed7-9bfcf0885a75" class="plotly-graph-div" style="height:100%; width:100%;"></div>
    <script type="text/javascript" src="/javascript/Function_Optimization/display_quadratic.js"></script>
</div>

<p>Next, we choose a random starting point and then run the SGD, Adam, and AdamW algorithms on this loss surface, using the same learning rate. The results are shown in the following figure</p>

<div>
    <script type="text/javascript">
        window.PlotlyConfig = {MathJaxConfig: 'local'};
    </script>
    <script type="text/javascript" src="/javascript/plotly.js"></script>
    <div id="ad28c67e-8fa6-4e48-93d1-b7dc05743f25" class="plotly-graph-div" style="height:100%; width:100%;"></div>
    <script type="text/javascript" src="/javascript/Function_Optimization/sgd_vs_adam_vs_adamw.js"></script>
</div>

<p>We can clearly see that Adam and AdamW, using the same parameters, choose the same path behaving in the same way, while SGD takes a different path that also stops far away from the local minimum with respect to the other algorithms. This highlights the advantage of adapting the learning rate instead of using a fixed learning rate.</p>
<p>In the following figure, we show how Adam outperform SGD on reaching the minima</p>
<p><img src="/images/Machine_Learning/sgd_vs_adam.gif" alt="SGD vs Adam"></p>
<h2 id="Conclusions-Further-Readings"><a href="#Conclusions-Further-Readings" class="headerlink" title="Conclusions &amp; Further Readings"></a>Conclusions &amp; Further Readings</h2><p>We have seen how the gradient descent can be used as a function optimizer. There are many optimizers in the wild, which one is better? There isn’t a unique answer. Some algorithms work better than others. As a rule of thumb, if you have sparse data, is preferable to use optimizers with an adaptive learning rate. SGD, generally, also performs well, but can be slow in certain scenarios. Selecting an appropriate learning rate, denoted as $\eta$, poses challenges: opting for a high value might lead to overshooting and missing the minima, whereas a lower value necessitates numerous steps to reach the minima. To tackle this issue, a methodology proposed in fastai, detailed in this <a target="_blank" rel="noopener" href="https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html">article</a>, can be employed. Similarly, for effectively determining other hyperparameters, the 1cycle policy presents a valuable approach.</p>
<p>We have only scratched the surface of the gradient descent algorithms. Numerous other variants exist, including <a target="_blank" rel="noopener" href="https://optimization.cbe.cornell.edu/index.php?title=RMSProp">RMSprop</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.09237v1.pdf">AMSGrad</a>, <a target="_blank" rel="noopener" href="https://golden.com/wiki/Adadelta">Adadelta</a>, and more. It’s important to acknowledge that gradient descent isn’t always the optimal optimization algorithm. Alternatives, such as the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions">Karush–Kuhn–Tucker (KKT) conditions</a> or <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Newton's_method_in_optimization">Newton’s method</a>, can offer greater efficiency and stability in certain cases.</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.offconvex.org/2016/03/22/saddlepoints/">https://www.offconvex.org/2016/03/22/saddlepoints/</a></li>
<li><a target="_blank" rel="noopener" href="https://optimization.cbe.cornell.edu/">https://optimization.cbe.cornell.edu/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.ruder.io/optimizing-gradient-descent/">https://www.ruder.io/optimizing-gradient-descent/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.fast.ai/posts/2018-07-02-adam-weight-decay.html">https://www.fast.ai/posts/2018-07-02-adam-weight-decay.html</a></li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>Gradient Descent explained</p><p><a href="https://captwake.github.io/Machine-Learning/GradientDescent-Explained/">https://captwake.github.io/Machine-Learning/GradientDescent-Explained/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Stefano De Rosa</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2023-08-24</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-09-07</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=64e4c5da4265f4001221c982&amp;product=inline-share-buttons&amp;source=platform" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/uncategorized/Understanding-Convolutions/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Understanding Convolutions</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/CTF-Write-Up/Cyberdefenders-GetPDF/"><span class="level-item">Cyberdefenders - GetPDF</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://captwake.github.io/Machine-Learning/GradientDescent-Explained/';
            this.page.identifier = 'Machine-Learning/GradientDescent-Explained/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'personal-blog-u9zciprq1a' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://avatars.githubusercontent.com/CaptWake" alt="Stefano De Rosa"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Stefano De Rosa</p><p class="is-size-6 is-block">Cybersecurity, Machine Learning</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Italy</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">0</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/CaptWake" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/CaptWake"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/CaptWake"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:stefano.derosa@proton.me"><i class="fas fa-envelope-square"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">1</span><span class="level-item">Introduction</span></span></a></li><li><a class="level is-mobile" href="#SGD"><span class="level-left"><span class="level-item">2</span><span class="level-item">SGD</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Mini-Batch-GD"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Mini-Batch GD</span></span></a></li><li><a class="level is-mobile" href="#Implementation"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">Implementation</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Adam"><span class="level-left"><span class="level-item">3</span><span class="level-item">Adam</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Implementation-1"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">Implementation</span></span></a></li></ul></li><li><a class="level is-mobile" href="#AdamW"><span class="level-left"><span class="level-item">4</span><span class="level-item">AdamW</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Implementation-2"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">Implementation</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Experiments"><span class="level-left"><span class="level-item">5</span><span class="level-item">Experiments</span></span></a></li><li><a class="level is-mobile" href="#Conclusions-Further-Readings"><span class="level-left"><span class="level-item">6</span><span class="level-item">Conclusions &amp; Further Readings</span></span></a></li><li><a class="level is-mobile" href="#References"><span class="level-left"><span class="level-item">7</span><span class="level-item">References</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/CTF-Write-Up/"><span class="level-start"><span class="level-item">CTF Write-Up</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Malware-Analysis/"><span class="level-start"><span class="level-item">Malware Analysis</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Windows-Internals/"><span class="level-start"><span class="level-item">Windows Internals</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/favicons/favicon-16x16.png" alt="Personal Blog" height="28"></a><p class="is-size-7"><span>&copy; 2023 Stefano De Rosa</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>